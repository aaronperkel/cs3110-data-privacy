{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5110: Data Privacy\n",
    "## Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "(Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html) of the textbook)\n",
    "\n",
    "Consider the following minimum query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual minimum age: 17\n",
      "Local sensitivity of the minimum: 17\n"
     ]
    }
   ],
   "source": [
    "## Cache the sorted ages, because we will use them a lot.\n",
    "age_lower = 0\n",
    "age_upper = 100\n",
    "sorted_ages = adult['Age'].clip(lower=age_lower, upper=age_upper).sort_values()\n",
    "\n",
    "def min_age():\n",
    "    clipped_ages = adult['Age'].clip(lower=0, upper=100)\n",
    "    return clipped_ages.min()\n",
    "\n",
    "def ls_min():\n",
    "    return max(sorted_ages.iloc[0] - age_lower, sorted_ages.iloc[1] - sorted_ages.iloc[0])\n",
    "\n",
    "print('Actual minimum age:', min_age())\n",
    "print('Local sensitivity of the minimum:', ls_min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `ls_min_at_distance`, an upper bound on the local sensitivity of the `min_age` query at distance $k$, and `dist_to_high_ls_min`, an upper bound on the distance from the true dataset to one with local sensitivity greater than or equal to $s_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e95fa87f9da6a780d2b7bfd34d9144e",
     "grade": false,
     "grade_id": "cell-63f79c9bbc970326",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ls_min_at_distance(k):\n",
    "    \"\"\"\n",
    "    Computes an upper bound on the local sensitivity of the min_age query at distance k.\n",
    "    \n",
    "    Parameters:\n",
    "    - k (int): The distance (number of record changes).\n",
    "    \n",
    "    Returns:\n",
    "    - float: The upper bound on local sensitivity at distance k.\n",
    "    \"\"\"\n",
    "    if k < 0:\n",
    "        raise ValueError(\"Distance k must be non-negative.\")\n",
    "    \n",
    "    n = len(sorted_ages)\n",
    "    \n",
    "    if k >= n:\n",
    "        # If k is greater than or equal to the number of records,\n",
    "        # all ages can be set to age_upper, so min_age becomes age_upper.\n",
    "        return age_upper\n",
    "    \n",
    "    if k < n - 1:\n",
    "        # When k < n-1, the new minimum can be the (k+1)-th smallest age\n",
    "        # and the new second minimum can be the (k+2)-th smallest age.\n",
    "        new_min = sorted_ages.iloc[k]\n",
    "        new_second_min = sorted_ages.iloc[k + 1]\n",
    "    else:\n",
    "        # When k == n-1, the new second minimum is age_upper.\n",
    "        new_min = sorted_ages.iloc[k]\n",
    "        new_second_min = age_upper\n",
    "    \n",
    "    # Compute the local sensitivity\n",
    "    return max(new_min - age_lower, new_second_min - new_min)\n",
    "\n",
    "def dist_to_high_ls_min(s_p):\n",
    "    \"\"\"\n",
    "    Computes an upper bound on the distance from the true dataset to one\n",
    "    with local sensitivity greater than or equal to s_p.\n",
    "    \n",
    "    Parameters:\n",
    "    - s_p (float): The target sensitivity.\n",
    "    \n",
    "    Returns:\n",
    "    - int: The minimum distance k such that ls_min_at_distance(k) >= s_p.\n",
    "           Returns len(sorted_ages) if no such k exists.\n",
    "    \"\"\"\n",
    "    if s_p <= 0:\n",
    "        return 0  # Any dataset satisfies s_p <= 0\n",
    "    \n",
    "    n = len(sorted_ages)\n",
    "    \n",
    "    for k in range(n + 1):\n",
    "        current_ls = ls_min_at_distance(k)\n",
    "        if current_ls >= s_p:\n",
    "            return k\n",
    "    return n  # If no k satisfies the condition, return the maximum distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f17aad1deca7916b4c5c752e39874646",
     "grade": true,
     "grade_id": "cell-09e957f0bec6bb1c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "assert dist_to_high_ls_min(18) == 395\n",
    "assert dist_to_high_ls_min(20) == 1657\n",
    "assert dist_to_high_ls_min(25) == 5570\n",
    "assert dist_to_high_ls_min(30) == 9711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "Implement `ptr_min`, which should use the propose-test-release framework to calculate a differentially private estimate of the minimum age. If the test fails, return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b84a9efbe0599f9888ad7bd5dae09ab",
     "grade": false,
     "grade_id": "cell-2c7d8b212cf7534c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-53.19900728593916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ptr_min(s_p, epsilon, delta):\n",
    "    \"\"\"\n",
    "    Implements the Propose-Test-Release (PTR) framework to compute a differentially private\n",
    "    estimate of the minimum age. If the test fails, returns None.\n",
    "    \n",
    "    Parameters:\n",
    "    - s_p (float): Proposed sensitivity.\n",
    "    - epsilon (float): Privacy parameter epsilon.\n",
    "    - delta (float): Privacy parameter delta.\n",
    "    \n",
    "    Returns:\n",
    "    - float or None: Noisy minimum age if the test passes; otherwise, None.\n",
    "    \"\"\"\n",
    "    # Step 1: Allocate privacy budget\n",
    "    epsilon_test = epsilon / 2\n",
    "    delta_test = delta / 2\n",
    "    epsilon_release = epsilon / 2\n",
    "    delta_release = delta / 2\n",
    "    \n",
    "    # Step 2: Compute the actual local sensitivity\n",
    "    actual_ls_min = ls_min()\n",
    "    \n",
    "    # Step 3: Compute the test statistic\n",
    "    test_stat = s_p - actual_ls_min\n",
    "    \n",
    "    # Step 4: Add Gaussian noise to the test statistic\n",
    "    sigma_test = np.sqrt(2 * np.log(1.25 / delta_test)) / epsilon_test\n",
    "    noisy_test_stat = test_stat + np.random.normal(0, sigma_test)\n",
    "    \n",
    "    # Step 5: Decide whether to release the noisy minimum\n",
    "    if noisy_test_stat >= 0:\n",
    "        # Test passes; release the noisy minimum\n",
    "        noisy_min = min_age() + np.random.laplace(0, s_p / epsilon_release)\n",
    "        return noisy_min\n",
    "    else:\n",
    "        # Test fails; do not release the minimum\n",
    "        return None\n",
    "\n",
    "\n",
    "# proposed sensitivity: 20\n",
    "# epsilon, delta = (1.0, 10^-5)\n",
    "ptr_min(20, 1.0, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405a713a0c16aa04953eaf620bece1c2",
     "grade": true,
     "grade_id": "cell-050c04785d3ca701",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m errors \u001b[38;5;241m=\u001b[39m [pct_error(true_min, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trials]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(errors))\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(errors) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(errors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m ptr_min(\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = min_age()\n",
    "trials = [ptr_min(20, 0.1, 1e-5) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print(np.mean(errors))\n",
    "assert np.mean(errors) < 2000\n",
    "assert np.mean(errors) > 500\n",
    "\n",
    "assert ptr_min(0.0001, 0.1, 1e-5) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (5 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- Can `ptr_min` give a useful answer for the minimum age?\n",
    "- If so, what is a good proposed sensitivity $s_p$ for the analyst to use? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4156433835b957fd4cda5c5c75ad190",
     "grade": true,
     "grade_id": "cell-9d80e40b356b7ba2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- Yes, `ptr_min` can provide a useful differentially private estimate of the minimum age, especially when the proposed sensitivity closely matches the actual local sensitivity of the dataset.\n",
    "- A good proposed sensitivity $s_p$ would be equal to or slightly greater than the true local sensitivity of the min_age query, which accounts for the smallest possible change in the minimum when up to $k$ records are modified. For instance, if the local sensitivity is known to be around 25, setting $s_p = 25$ ensures that the PTR framework is more likely to pass the sensitivity test, thereby yielding a meaningful and accurate noisy minimum age while maintaining differential privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the average capital gain in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f06b7e80865199f7d442753802103a",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059918",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562.7246675211478"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.mean()\n",
    "\n",
    "def saa_avg_capgain(k, epsilon):\n",
    "    \"\"\"\n",
    "    Implements the Sample-and-Aggregate framework to release a differentially private\n",
    "    estimate of the average capital gain in the adult dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - k (int): Number of disjoint subsets to split the data into.\n",
    "    - epsilon (float): Privacy parameter epsilon.\n",
    "\n",
    "    Returns:\n",
    "    - float: Noisy average capital gain if successful.\n",
    "    - None: If aggregation fails (e.g., due to insufficient data).\n",
    "    \"\"\"\n",
    "    # Step 1: Extract the 'CapitalGain' column and handle missing values if any\n",
    "    capital_gains = adult['Capital Gain'].dropna().values  # Corrected column name\n",
    "    n = len(capital_gains)\n",
    "\n",
    "    if k <= 0:\n",
    "        raise ValueError(\"Number of subsets k must be positive.\")\n",
    "    if k > n:\n",
    "        raise ValueError(\"Number of subsets k cannot exceed the number of data points.\")\n",
    "\n",
    "    # Step 2: Split the data into k disjoint subsets\n",
    "    # Shuffle the data to ensure random partitioning\n",
    "    np.random.shuffle(capital_gains)\n",
    "    subsets = np.array_split(capital_gains, k)\n",
    "\n",
    "    # Step 3: Compute the mean capital gain for each subset\n",
    "    subset_means = [f(chunk) for chunk in subsets]\n",
    "\n",
    "    # Step 4: Aggregate the subset means using a robust aggregator (e.g., median)\n",
    "    # Median is chosen for its robustness to outliers\n",
    "    aggregate_mean = np.median(subset_means)\n",
    "\n",
    "    # Step 5: Determine the sensitivity of the aggregation\n",
    "    # Assuming CapitalGain is clipped between 0 and 10000\n",
    "    capgain_lower = 0\n",
    "    capgain_upper = 10000\n",
    "    subset_size = n // k\n",
    "    sensitivity = (capgain_upper - capgain_lower) / subset_size\n",
    "\n",
    "    # Step 6: Add Laplace noise to the aggregate_mean to ensure differential privacy\n",
    "    noisy_aggregate = laplace_mech(aggregate_mean, sensitivity, epsilon)\n",
    "\n",
    "    return noisy_aggregate\n",
    "\n",
    "saa_avg_capgain(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17f040565db3bbce3280c6867ad7a7bd",
     "grade": true,
     "grade_id": "cell-d325061161621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 35.28141170125243\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage error:\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(errors))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(errors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(errors) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Capital Gain'].mean()\n",
    "trials = [saa_avg_capgain(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the minimum age in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bebe49c9db6596a78b95f6b14f803936",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059908",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.64365771813804"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.min()\n",
    "\n",
    "def saa_min_age(k, epsilon):\n",
    "    \"\"\"\n",
    "    Implements the Sample-and-Aggregate (SAA) framework to release a differentially private\n",
    "    estimate of the minimum age in the adult dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - k (int): Number of disjoint subsets to split the data into.\n",
    "    - epsilon (float): Privacy parameter epsilon.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Noisy minimum age if successful.\n",
    "    - None: If aggregation fails (e.g., due to insufficient data).\n",
    "    \"\"\"\n",
    "    # Step 1: Extract the 'Age' column and handle missing values if any\n",
    "    capital_gains = adult['Age'].dropna().values\n",
    "    n = len(capital_gains)\n",
    "    \n",
    "    # Define the clipping bounds based on the dataset (from Question 1)\n",
    "    age_lower = 0\n",
    "    age_upper = 100\n",
    "    \n",
    "    if k <= 0:\n",
    "        raise ValueError(\"Number of subsets k must be positive.\")\n",
    "    if k > n:\n",
    "        raise ValueError(\"Number of subsets k cannot exceed the number of data points.\")\n",
    "    \n",
    "    # Step 2: Split the data into k disjoint subsets\n",
    "    # Shuffle the data to ensure random partitioning\n",
    "    np.random.shuffle(capital_gains)\n",
    "    subsets = np.array_split(capital_gains, k)\n",
    "    \n",
    "    # Step 3: Compute the minimum age for each subset\n",
    "    subset_mins = [f(chunk) for chunk in subsets]\n",
    "    \n",
    "    # Step 4: Aggregate the subset minima using a robust aggregator (e.g., median)\n",
    "    # Median is chosen for its robustness against outliers\n",
    "    aggregate_min = np.median(subset_mins)\n",
    "    \n",
    "    # Step 5: Determine the sensitivity of the aggregation\n",
    "    # Sensitivity for min aggregator in SAA:\n",
    "    # Each subset's min can change by at most (age_upper - age_lower)\n",
    "    # Thus, the sensitivity is (age_upper - age_lower) / k\n",
    "    sensitivity = (age_upper - age_lower) / k\n",
    "    \n",
    "    # Step 6: Add Laplace noise to the aggregate_min to ensure differential privacy\n",
    "    noisy_min = laplace_mech(aggregate_min, sensitivity, epsilon)\n",
    "    \n",
    "    return noisy_min\n",
    "\n",
    "saa_min_age(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b236935f249e21a80f2b0c8b8a1b7722",
     "grade": true,
     "grade_id": "cell-d325061167621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 1.3181875683061144\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Age'].min()\n",
    "trials = [saa_min_age(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "In 5-6 sentences, answer the following:\n",
    "\n",
    "- What clipping values did you choose for clipping the query outputs on each chunk? How did you pick them? Does the best choice differ between questions 4 and 5?\n",
    "- Is 500 a good value for the number of chunks $k$? How does making $k$ larger or smaller change the results? Does the best choice differ between questions 4 and 5?\n",
    "- How does the sample-and-aggregate approach compare to propose-test-release or global sensitivity for the minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "509f0c56c158e6f504dd5091e1050e7b",
     "grade": true,
     "grade_id": "cell-4bbbc2dba075a1e5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "For Question 4, which involves releasing the average capital gain, I chose to clip the capital gain values between 0 and 10,000. These bounds were selected based on the observed range in the dataset to limit the influence of extreme outliers and control the sensitivity of the mean calculation. In Question 5, where the task is to release the minimum age, I clipped the ages between 0 and 100, aligning with realistic human age ranges and the dataset’s constraints. The clipping values differ between the two questions because they pertain to different attributes with distinct natural bounds.\n",
    "\n",
    "Choosing $k = 500$ for the number of chunks strikes a balance between utility and privacy. A larger k reduces the sensitivity by distributing data across more subsets, which can enhance privacy but may introduce more noise due to smaller subset sizes. Conversely, a smaller $k$ increases sensitivity but can improve the accuracy of the aggregated results. The optimal $k$ may vary between questions 4 and 5 because the sensitivity and data distribution differ for averaging capital gains versus finding the minimum age.\n",
    "\n",
    "Compared to the Propose-Test-Release (PTR) framework or using global sensitivity directly for the minimum age query, the Sample-and-Aggregate (SAA) approach offers greater robustness. While PTR requires accurately proposing a sensitivity and may fail if the proposal is inadequate, SAA inherently manages sensitivity through data partitioning and robust aggregation (like the median). Additionally, global sensitivity for the minimum can be overly restrictive and less practical, whereas SAA provides a more flexible and scalable method for complex queries like finding the minimum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
