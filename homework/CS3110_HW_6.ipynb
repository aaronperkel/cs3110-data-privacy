{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5110: Data Privacy\n",
    "## Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "(Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html) of the textbook)\n",
    "\n",
    "Consider the following minimum query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual minimum age: 17\n",
      "Local sensitivity of the minimum: 17\n"
     ]
    }
   ],
   "source": [
    "## Cache the sorted ages, because we will use them a lot.\n",
    "age_lower = 0\n",
    "age_upper = 100\n",
    "sorted_ages = adult['Age'].clip(lower=age_lower, upper=age_upper).sort_values()\n",
    "\n",
    "def min_age():\n",
    "    clipped_ages = adult['Age'].clip(lower=0, upper=100)\n",
    "    return clipped_ages.min()\n",
    "\n",
    "def ls_min():\n",
    "    return max(sorted_ages.iloc[0] - age_lower, sorted_ages.iloc[1] - sorted_ages.iloc[0])\n",
    "\n",
    "print('Actual minimum age:', min_age())\n",
    "print('Local sensitivity of the minimum:', ls_min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `ls_min_at_distance`, an upper bound on the local sensitivity of the `min_age` query at distance $k$, and `dist_to_high_ls_min`, an upper bound on the distance from the true dataset to one with local sensitivity greater than or equal to $s_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e95fa87f9da6a780d2b7bfd34d9144e",
     "grade": false,
     "grade_id": "cell-63f79c9bbc970326",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ls_min_at_distance(k):\n",
    "    return max(sorted_ages.iloc[k] - age_lower, sorted_ages.iloc[1] - sorted_ages.iloc[0])\n",
    "\n",
    "def dist_to_high_ls_min(s_p):\n",
    "    k = 0\n",
    "    while ls_min_at_distance(k) < s_p:\n",
    "        k += 1\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f17aad1deca7916b4c5c752e39874646",
     "grade": true,
     "grade_id": "cell-09e957f0bec6bb1c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "assert dist_to_high_ls_min(18) == 395\n",
    "assert dist_to_high_ls_min(20) == 1657\n",
    "assert dist_to_high_ls_min(25) == 5570\n",
    "assert dist_to_high_ls_min(30) == 9711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "Implement `ptr_min`, which should use the propose-test-release framework to calculate a differentially private estimate of the minimum age. If the test fails, return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b84a9efbe0599f9888ad7bd5dae09ab",
     "grade": false,
     "grade_id": "cell-2c7d8b212cf7534c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12318    24.921112\n",
       "6312     24.921112\n",
       "30927    24.921112\n",
       "12787    24.921112\n",
       "25755    24.921112\n",
       "           ...    \n",
       "24043    97.921112\n",
       "32277    97.921112\n",
       "5104     97.921112\n",
       "8963     97.921112\n",
       "10210    97.921112\n",
       "Name: Age, Length: 32561, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ptr_min(s_p, epsilon, delta):\n",
    "    s = s_p\n",
    "    dist = dist_to_high_ls_min(s)\n",
    "    noisy_dist = laplace_mech(dist, sensitivity=1, epsilon=epsilon)\n",
    "    test_r = noisy_dist < np.log(2/delta)/(2*epsilon)\n",
    "    \n",
    "    if test_r:\n",
    "        return None\n",
    "    result = sorted_ages\n",
    "    return laplace_mech(result, sensitivity=s, epsilon=epsilon)\n",
    "\n",
    "# proposed sensitivity: 20\n",
    "# epsilon, delta = (1.0, 10^-5)\n",
    "ptr_min(20, 1.0, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405a713a0c16aa04953eaf620bece1c2",
     "grade": true,
     "grade_id": "cell-050c04785d3ca701",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535.345940050963\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = min_age()\n",
    "trials = [ptr_min(20, 0.1, 1e-5) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print(np.mean(errors))\n",
    "assert np.mean(errors) < 2000\n",
    "assert np.mean(errors) > 500\n",
    "\n",
    "assert ptr_min(0.0001, 0.1, 1e-5) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (5 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- Can `ptr_min` give a useful answer for the minimum age?\n",
    "- If so, what is a good proposed sensitivity $s_p$ for the analyst to use? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4156433835b957fd4cda5c5c75ad190",
     "grade": true,
     "grade_id": "cell-9d80e40b356b7ba2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- **Yes, `ptr_min` can provide a useful differentially private estimate of the minimum age.** The effectiveness of ptr_min hinges on how well the proposed sensitivity $s_p$ aligns with the actual local sensitivity of the dataset. By accurately estimating or bounding the local sensitivity, ptr_min can reliably determine whether to release a noisy minimum or abstain, thus maintaining differential privacy while providing meaningful insights.\n",
    "- **A good proposed sensitivity $s_p$ should be equal to or slightly greater than the true local sensitivity of the `min_age` query.** In your implementation, the actual local sensitivity was determined based on the dataset’s characteristics. For instance, if the local sensitivity is around 20 (as per your test cases), setting $s_p = 20$ ensures that the PTR framework has a high probability of passing the sensitivity test. This balance allows for the release of a noisy minimum that is both privacy-preserving and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the average capital gain in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f06b7e80865199f7d442753802103a",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059918",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052.407142183598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.mean()\n",
    "\n",
    "def saa_avg_capgain(k, epsilon):\n",
    "    data = adult['Capital Gain']\n",
    "    chunks = np.array_split(data, k)\n",
    "    answers = [f(chunk) for chunk in chunks]\n",
    "    answers_clipped = pd.Series(answers).clip(upper=10000)\n",
    "    answes_clipped_avg = answers_clipped.mean()\n",
    "    noisy_answers_clipped_avg = laplace_mech(answes_clipped_avg, sensitivity=10000/k, epsilon=epsilon)\n",
    "    \n",
    "    return noisy_answers_clipped_avg\n",
    "\n",
    "saa_avg_capgain(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17f040565db3bbce3280c6867ad7a7bd",
     "grade": true,
     "grade_id": "cell-d325061161621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 1.6978131448810516\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Capital Gain'].mean()\n",
    "trials = [saa_avg_capgain(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the minimum age in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bebe49c9db6596a78b95f6b14f803936",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059908",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.79190828695387"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.min()\n",
    "\n",
    "def saa_min_age(k, epsilon):\n",
    "    data = adult['Age']\n",
    "    chunks = np.array_split(data, k)\n",
    "    answers = [f(chunk) for chunk in chunks]\n",
    "    answers_clipped = pd.Series(answers).clip(upper=50)\n",
    "    answes_clipped_avg = answers_clipped.mean()\n",
    "    noisy_answers_clipped_avg = laplace_mech(answes_clipped_avg, sensitivity=50/k, epsilon=epsilon)\n",
    "    \n",
    "    return noisy_answers_clipped_avg\n",
    "\n",
    "saa_min_age(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b236935f249e21a80f2b0c8b8a1b7722",
     "grade": true,
     "grade_id": "cell-d325061167621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 3.4537333500633176\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Age'].min()\n",
    "trials = [saa_min_age(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "In 5-6 sentences, answer the following:\n",
    "\n",
    "- What clipping values did you choose for clipping the query outputs on each chunk? How did you pick them? Does the best choice differ between questions 4 and 5?\n",
    "- Is 500 a good value for the number of chunks $k$? How does making $k$ larger or smaller change the results? Does the best choice differ between questions 4 and 5?\n",
    "- How does the sample-and-aggregate approach compare to propose-test-release or global sensitivity for the minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "509f0c56c158e6f504dd5091e1050e7b",
     "grade": true,
     "grade_id": "cell-4bbbc2dba075a1e5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- **Clipping Values:**\n",
    "    - **For Question 4 (Average Capital Gain):** I clipped the capital gain values between 0 and 10,000, which effectively limits the influence of extreme outliers and controls the sensitivity of the mean calculation.\n",
    "    - **For Question 5 (Minimum Age):** I clipped the ages between 0 and 50. This tighter bound further reduces sensitivity, as the range within which ages can vary is narrower.\n",
    "    - **Difference:** The clipping values differ because they pertain to different attributes with distinct natural bounds and data distributions. The minimum age’s upper bound was reduced to 50 to better reflect realistic age distributions and further control sensitivity.\n",
    "- **Number of Chunks $k=500$:**\n",
    "    - **Rationale:** Choosing $k = 500$ strikes a balance between utility and privacy by distributing data across numerous subsets.\n",
    "\t- **Effect of Larger $k$:** Further reduces sensitivity by dividing data into more subsets, which can enhance privacy. However, it may introduce more noise due to smaller subset sizes, potentially impacting accuracy.\n",
    "\t- **Effect of Smaller $k$:** Increases sensitivity as data is concentrated in fewer subsets, potentially reducing noise but compromising privacy.\n",
    "\t- **Difference Between Q4 and Q5:** While $k = 500$ works well for both questions, the optimal $k$  might differ based on the specific sensitivity and data distribution of each query. For example, tighter clipping in Q5 allows for a higher $k$ without excessively increasing noise, whereas Q4 might require a slightly different balance.\n",
    "-   **Comparison of SAA to PTR and Global Sensitivity:**\n",
    "\t- **Robustness:** The Sample-and-Aggregate (SAA) approach offers greater robustness compared to the Propose-Test-Release (PTR) framework by inherently managing sensitivity through data partitioning and robust aggregation methods like the median.\n",
    "\t- **Flexibility:** Unlike PTR, which necessitates accurate sensitivity proposals and may fail if the proposal is inadequate, SAA provides a more flexible and scalable method suitable for complex queries such as finding the minimum.\n",
    "\t- **Global Sensitivity:** Using global sensitivity for queries like the minimum age can be overly restrictive and less practical, as it doesn’t account for the actual data distribution. In contrast, SAA leverages data partitioning to achieve a more practical sensitivity estimate, enhancing both privacy and utility.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
