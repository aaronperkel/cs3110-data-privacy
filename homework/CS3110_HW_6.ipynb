{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5110: Data Privacy\n",
    "## Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "(Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html) of the textbook)\n",
    "\n",
    "Consider the following minimum query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual minimum age: 17\n",
      "Local sensitivity of the minimum: 17\n"
     ]
    }
   ],
   "source": [
    "## Cache the sorted ages, because we will use them a lot.\n",
    "age_lower = 0\n",
    "age_upper = 100\n",
    "sorted_ages = adult['Age'].clip(lower=age_lower, upper=age_upper).sort_values()\n",
    "\n",
    "def min_age():\n",
    "    clipped_ages = adult['Age'].clip(lower=0, upper=100)\n",
    "    return clipped_ages.min()\n",
    "\n",
    "def ls_min():\n",
    "    return max(sorted_ages.iloc[0] - age_lower, sorted_ages.iloc[1] - sorted_ages.iloc[0])\n",
    "\n",
    "print('Actual minimum age:', min_age())\n",
    "print('Local sensitivity of the minimum:', ls_min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `ls_min_at_distance`, an upper bound on the local sensitivity of the `min_age` query at distance $k$, and `dist_to_high_ls_min`, an upper bound on the distance from the true dataset to one with local sensitivity greater than or equal to $s_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e95fa87f9da6a780d2b7bfd34d9144e",
     "grade": false,
     "grade_id": "cell-63f79c9bbc970326",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ls_min_at_distance(k):\n",
    "    return max(sorted_ages.iloc[k] - age_lower, sorted_ages.iloc[1] - sorted_ages.iloc[0])\n",
    "\n",
    "def dist_to_high_ls_min(s_p):\n",
    "    k = 0\n",
    "    while ls_min_at_distance(k) < s_p:\n",
    "        k += 1\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f17aad1deca7916b4c5c752e39874646",
     "grade": true,
     "grade_id": "cell-09e957f0bec6bb1c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "assert dist_to_high_ls_min(18) == 395\n",
    "assert dist_to_high_ls_min(20) == 1657\n",
    "assert dist_to_high_ls_min(25) == 5570\n",
    "assert dist_to_high_ls_min(30) == 9711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "Implement `ptr_min`, which should use the propose-test-release framework to calculate a differentially private estimate of the minimum age. If the test fails, return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b84a9efbe0599f9888ad7bd5dae09ab",
     "grade": false,
     "grade_id": "cell-2c7d8b212cf7534c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12318    24.921112\n",
       "6312     24.921112\n",
       "30927    24.921112\n",
       "12787    24.921112\n",
       "25755    24.921112\n",
       "           ...    \n",
       "24043    97.921112\n",
       "32277    97.921112\n",
       "5104     97.921112\n",
       "8963     97.921112\n",
       "10210    97.921112\n",
       "Name: Age, Length: 32561, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ptr_min(s_p, epsilon, delta):\n",
    "    s = s_p\n",
    "    dist = dist_to_high_ls_min(s)\n",
    "    noisy_dist = laplace_mech(dist, sensitivity=1, epsilon=epsilon)\n",
    "    test_r = noisy_dist < np.log(2/delta)/(2*epsilon)\n",
    "    \n",
    "    if test_r:\n",
    "        return None\n",
    "    result = sorted_ages\n",
    "    return laplace_mech(result, sensitivity=s, epsilon=epsilon)\n",
    "\n",
    "# proposed sensitivity: 20\n",
    "# epsilon, delta = (1.0, 10^-5)\n",
    "ptr_min(20, 1.0, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405a713a0c16aa04953eaf620bece1c2",
     "grade": true,
     "grade_id": "cell-050c04785d3ca701",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535.345940050963\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = min_age()\n",
    "trials = [ptr_min(20, 0.1, 1e-5) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print(np.mean(errors))\n",
    "assert np.mean(errors) < 2000\n",
    "assert np.mean(errors) > 500\n",
    "\n",
    "assert ptr_min(0.0001, 0.1, 1e-5) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (5 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- Can `ptr_min` give a useful answer for the minimum age?\n",
    "- If so, what is a good proposed sensitivity $s_p$ for the analyst to use? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4156433835b957fd4cda5c5c75ad190",
     "grade": true,
     "grade_id": "cell-9d80e40b356b7ba2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- **Yes, `ptr_min` can provide a useful differentially private estimate of the minimum age.** The effectiveness of ptr_min hinges on how well the proposed sensitivity $s_p$ aligns with the actual local sensitivity of the dataset. By accurately estimating or bounding the local sensitivity, ptr_min can reliably determine whether to release a noisy minimum or abstain, thus maintaining differential privacy while providing meaningful insights.\n",
    "- **A good proposed sensitivity $s_p$ should be equal to or slightly greater than the true local sensitivity of the `min_age` query.** In your implementation, the actual local sensitivity was determined based on the datasetâ€™s characteristics. For instance, if the local sensitivity is around 20 (as per your test cases), setting $s_p = 20$ ensures that the PTR framework has a high probability of passing the sensitivity test. This balance allows for the release of a noisy minimum that is both privacy-preserving and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the average capital gain in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f06b7e80865199f7d442753802103a",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059918",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052.407142183598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.mean()\n",
    "\n",
    "def saa_avg_capgain(k, epsilon):\n",
    "    data = adult['Capital Gain']\n",
    "    chunks = np.array_split(data, k)\n",
    "    answers = [f(chunk) for chunk in chunks]\n",
    "    answers_clipped = pd.Series(answers).clip(upper=10000)\n",
    "    answes_clipped_avg = answers_clipped.mean()\n",
    "    noisy_answers_clipped_avg = laplace_mech(answes_clipped_avg, sensitivity=10000/k, epsilon=epsilon)\n",
    "    \n",
    "    return noisy_answers_clipped_avg\n",
    "\n",
    "saa_avg_capgain(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17f040565db3bbce3280c6867ad7a7bd",
     "grade": true,
     "grade_id": "cell-d325061161621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 1.6978131448810516\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Capital Gain'].mean()\n",
    "trials = [saa_avg_capgain(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Use the sample-and-aggregate framework to release the minimum age in the adult dataset. Reference [Chapter 7](https://uvm-plaid.github.io/programming-dp/notebooks/ch7.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bebe49c9db6596a78b95f6b14f803936",
     "grade": false,
     "grade_id": "cell-de5a77cbd2059908",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.79190828695387"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(chunk):\n",
    "    return chunk.min()\n",
    "\n",
    "def saa_min_age(k, epsilon):\n",
    "    data = adult['Age']\n",
    "    chunks = np.array_split(data, k)\n",
    "    answers = [f(chunk) for chunk in chunks]\n",
    "    answers_clipped = pd.Series(answers).clip(upper=50)\n",
    "    answes_clipped_avg = answers_clipped.mean()\n",
    "    noisy_answers_clipped_avg = laplace_mech(answes_clipped_avg, sensitivity=50/k, epsilon=epsilon)\n",
    "    \n",
    "    return noisy_answers_clipped_avg\n",
    "\n",
    "saa_min_age(500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b236935f249e21a80f2b0c8b8a1b7722",
     "grade": true,
     "grade_id": "cell-d325061167621b36",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 3.4537333500633176\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE\n",
    "true_min = adult['Age'].min()\n",
    "trials = [saa_min_age(500, 1.0) for _ in range(20)]\n",
    "errors = [pct_error(true_min, t) for t in trials]\n",
    "print('Average error:', np.mean(errors))\n",
    "assert np.mean(errors) > 0\n",
    "assert np.mean(errors) < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "In 5-6 sentences, answer the following:\n",
    "\n",
    "- What clipping values did you choose for clipping the query outputs on each chunk? How did you pick them? Does the best choice differ between questions 4 and 5?\n",
    "- Is 500 a good value for the number of chunks $k$? How does making $k$ larger or smaller change the results? Does the best choice differ between questions 4 and 5?\n",
    "- How does the sample-and-aggregate approach compare to propose-test-release or global sensitivity for the minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "509f0c56c158e6f504dd5091e1050e7b",
     "grade": true,
     "grade_id": "cell-4bbbc2dba075a1e5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- **Clipping Values:**\n",
    "    - **For Question 4 (Average Capital Gain):** I clipped the capital gain values between 0 and 10,000, which effectively limits the influence of extreme outliers and controls the sensitivity of the mean calculation.\n",
    "    - **For Question 5 (Minimum Age):** I clipped the ages between 0 and 50. This tighter bound further reduces sensitivity, as the range within which ages can vary is narrower.\n",
    "    - **Difference:** The clipping values differ because they pertain to different attributes with distinct natural bounds and data distributions. The minimum ageâ€™s upper bound was reduced to 50 to better reflect realistic age distributions and further control sensitivity.\n",
    "- **Number of Chunks $k=500$:**\n",
    "    - **Rationale:** Choosing $k = 500$ strikes a balance between utility and privacy by distributing data across numerous subsets.\n",
    "\t- **Effect of Larger $k$:** Further reduces sensitivity by dividing data into more subsets, which can enhance privacy. However, it may introduce more noise due to smaller subset sizes, potentially impacting accuracy.\n",
    "\t- **Effect of Smaller $k$:** Increases sensitivity as data is concentrated in fewer subsets, potentially reducing noise but compromising privacy.\n",
    "\t- **Difference Between Q4 and Q5:** While $k = 500$ works well for both questions, the optimal $k$  might differ based on the specific sensitivity and data distribution of each query. For example, tighter clipping in Q5 allows for a higher $k$ without excessively increasing noise, whereas Q4 might require a slightly different balance.\n",
    "-   **Comparison of SAA to PTR and Global Sensitivity:**\n",
    "\t- **Robustness:** The Sample-and-Aggregate (SAA) approach offers greater robustness compared to the Propose-Test-Release (PTR) framework by inherently managing sensitivity through data partitioning and robust aggregation methods like the median.\n",
    "\t- **Flexibility:** Unlike PTR, which necessitates accurate sensitivity proposals and may fail if the proposal is inadequate, SAA provides a more flexible and scalable method suitable for complex queries such as finding the minimum.\n",
    "\t- **Global Sensitivity:** Using global sensitivity for queries like the minimum age can be overly restrictive and less practical, as it doesnâ€™t account for the actual data distribution. In contrast, SAA leverages data partitioning to achieve a more practical sensitivity estimate, enhancing both privacy and utility.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
