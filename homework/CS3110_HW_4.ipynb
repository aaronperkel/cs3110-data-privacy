{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5990: Data Privacy\n",
    "## Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Complete the definition of `dp_sum_capgain` below. Your definition should compute a differentially private sum of the \"Capital Gain\" column of the `adult` dataset, and have a total privacy cost of `epsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6080971c67250edb52282f4b23cd5b88",
     "grade": false,
     "grade_id": "cell-6a369f61d8eef943",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35048384.163850926"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_sum_capgain(epsilon):\n",
    "    capgain_sum = adult[\"Capital Gain\"].sum()\n",
    "    sensitivity = adult[\"Capital Gain\"].max()\n",
    "\n",
    "    dp_sum = laplace_mech(capgain_sum, sensitivity=sensitivity, epsilon=epsilon)\n",
    "    return dp_sum\n",
    "\n",
    "dp_sum_capgain(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9fcd394127b5d73aac00552e7e7ab4",
     "grade": true,
     "grade_id": "cell-e5b1229ba2249f71",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 1.9499730772877641 0.29039905950370454 0.026207578820291125\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 1\n",
    "\n",
    "real_sum = adult['Capital Gain'].sum()\n",
    "r1 = np.mean([pct_error(real_sum, dp_sum_capgain(0.1)) for _ in range(100)])\n",
    "r2 = np.mean([pct_error(real_sum, dp_sum_capgain(1.0)) for _ in range(100)])\n",
    "r3 = np.mean([pct_error(real_sum, dp_sum_capgain(10.0)) for _ in range(100)])\n",
    "\n",
    "print(\"Average errors:\", r1, r2, r3)\n",
    "\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 10\n",
    "assert r2 < 2\n",
    "assert r3 < 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- What clipping parameter did you use in your definition of `dp_sum_capital`, and why?\n",
    "- What was the sensitivity of the query you used in `dp_sum_capital`, and how is it bounded?\n",
    "- Argue that your definition of `dp_sum_capital` has a total privacy cost of `epsilon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cfdb579dfcf330b8e9e9cfd697fe494",
     "grade": true,
     "grade_id": "cell-986eec754f32c072",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1.\tWhat clipping parameter did you use in your definition of dp_sum_capital, and why?\n",
    "- I did not use an explicit clipping parameter in the implementation of dp_sum_capgain. Instead, I used the maximum value in the “Capital Gain” column as the sensitivity, which inherently serves as a form of clipping by bounding the maximum possible change to the sum query. This ensures that outliers do not disproportionately affect the noise added for privacy.\n",
    "2. What was the sensitivity of the query you used in dp_sum_capital, and how is it bounded?\n",
    "- The sensitivity of the sum query is the maximum value of the “Capital Gain” column in the dataset, which is bounded because the values in the dataset are finite. Sensitivity is calculated as the difference in the sum caused by the addition or removal of one individual, and it is bounded by the largest possible individual “Capital Gain.”\n",
    "3. Argue that your definition of dp_sum_capital has a total privacy cost of epsilon.\n",
    "- The total privacy cost of the dp_sum_capgain function is epsilon because the Laplace mechanism is used with a noise scale of sensitivity / epsilon. By adding noise proportional to the sensitivity divided by epsilon, we ensure that the probability of any particular outcome changes only by a factor of exp(epsilon), thus satisfying differential privacy with a privacy cost of exactly epsilon for this query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Complete the definition of `dp_avg_capgain` below. Your definition should compute a differentially private average (mean) of the \"Capital Gain\" column of the adult dataset, and have a **total privacy cost of epsilon**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99b884a40ae754582e5d08c98abb1fda",
     "grade": false,
     "grade_id": "cell-93f2a5153dca0e95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076.964727297736"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_avg_capgain(epsilon):\n",
    "    capgain_sum = adult[\"Capital Gain\"].sum()\n",
    "    capgain_count = len(adult[\"Capital Gain\"])\n",
    "\n",
    "    sum_sensitivity = adult[\"Capital Gain\"].max()\n",
    "    count_sensitivity = 1\n",
    "\n",
    "    noisy_sum = laplace_mech(capgain_sum, sum_sensitivity, epsilon/2)\n",
    "    noisy_count = laplace_mech(capgain_count, count_sensitivity, epsilon/2)\n",
    "\n",
    "    dp_avg = noisy_sum / noisy_count\n",
    "\n",
    "    return dp_avg\n",
    "\n",
    "dp_avg_capgain(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1b47ee125ecebaab842c8677f424806",
     "grade": true,
     "grade_id": "cell-ef77b325b5c58908",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 6.229336943600658 0.5495139105254281 0.05916032350313569\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 3\n",
    "\n",
    "real_avg = adult['Capital Gain'].mean()\n",
    "r1 = np.mean([pct_error(real_avg, dp_avg_capgain(0.1)) for _ in range(100)])\n",
    "r2 = np.mean([pct_error(real_avg, dp_avg_capgain(1.0)) for _ in range(100)])\n",
    "r3 = np.mean([pct_error(real_avg, dp_avg_capgain(10.0)) for _ in range(100)])\n",
    "\n",
    "print(\"Average errors:\", r1, r2, r3)\n",
    "\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 20\n",
    "assert r2 < 4\n",
    "assert r3 < 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- Argue that your definition of `dp_avg_capgain` has a total privacy cost of `epsilon`\n",
    "- For sums and averages, which seems to be more important for accuracy - the value of the clipping parameter $b$ or the scale of the noise added? Why?\n",
    "- Do you think the answer to the previous point will be true for every dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bdbfc10631a501c5a7fb556dd93b78b",
     "grade": true,
     "grade_id": "cell-7ea16016366529bd",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Argue that your definition of dp_avg_capgain has a total privacy cost of epsilon.\n",
    "- The privacy cost of the dp_avg_capgain function is epsilon because we split the privacy budget between the sum and the count operations, assigning epsilon/2 to each. The Laplace mechanism guarantees that each query (sum and count) is individually protected by differential privacy with its allocated epsilon/2. Since the queries are independent, the total privacy cost is the sum of their individual costs, resulting in a total privacy cost of epsilon.\n",
    "2. For sums and averages, which seems to be more important for accuracy - the value of the clipping parameter  b  or the scale of the noise added? Why?\n",
    "- The scale of the noise added seems to be more important for accuracy, especially when the noise is large relative to the magnitude of the sum or average. Larger noise (resulting from smaller values of  \\epsilon ) can greatly distort the result, whereas the clipping parameter  b , which bounds the sensitivity, primarily affects outlier influence. In many cases, the noise overwhelms the effect of clipping if the sensitivity is not extreme.\n",
    "3. Do you think the answer to the previous point will be true for every dataset? Why or why not?\n",
    "- This answer may not hold true for every dataset. In datasets with extreme outliers or a wide range of values, the clipping parameter  b  plays a more critical role in maintaining accuracy. If the clipping parameter is too large, extreme values can distort the result, while if it is too small, valid data may be lost. In datasets with more uniform data, the scale of the noise becomes the primary factor influencing accuracy. Therefore, the relative importance of noise and clipping depends on the specific characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Write a function `auto_avg` that returns the differentially private average of a Pandas series `s`. Your function should automatically determine the clipping parameter `b`, and should enforce differential privacy for a **total privacy cost** of `epsilon`. You can assume that all values are non-negative (i.e. 0 or greater)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2904d4ac725862cfa5bf5407dac205ad",
     "grade": false,
     "grade_id": "cell-10b352b38a9b5f85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635.2078500554668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def auto_avg(s, epsilon):\n",
    "    if s.max() < 100:\n",
    "        b = np.percentile(s, 95)\n",
    "    else:\n",
    "        b = np.percentile(s, 99)\n",
    "    \n",
    "    s_clipped = np.clip(s, 0, b)\n",
    "    sum_clipped = s_clipped.sum()\n",
    "    count_clipped = len(s_clipped)\n",
    "\n",
    "    sum_sensitivity = b\n",
    "    count_sensitivity = 1\n",
    "\n",
    "    noisy_sum = laplace_mech(sum_clipped, sum_sensitivity, epsilon/2)\n",
    "    noisy_count = laplace_mech(count_clipped, count_sensitivity, epsilon/2)\n",
    "\n",
    "    noisy_count = max(noisy_count, 1e-3)\n",
    "    dp_avg = noisy_sum / noisy_count\n",
    "\n",
    "    return dp_avg\n",
    "\n",
    "auto_avg(adult['Capital Gain'], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "681c071e3c768c39363da9bc07e17e2b",
     "grade": true,
     "grade_id": "cell-49fb57b1ebfcc0da",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 0.8541702889354614 41.18474165789031 0.6573477104725857\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 5\n",
    "r1 = np.mean([pct_error(adult['Age'].mean(), auto_avg(adult['Age'], 1.0)) for _ in range(20)])\n",
    "r2 = np.mean([pct_error(adult['Capital Gain'].mean(), auto_avg(adult['Capital Gain'], 1.0)) for _ in range(20)])\n",
    "r3 = np.mean([pct_error(adult['fnlwgt'].mean(), auto_avg(adult['fnlwgt'], 1.0)) for _ in range(20)])\n",
    "\n",
    "print('Average errors:', r1, r2, r3)\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 1\n",
    "assert r2 < 100\n",
    "assert r3 < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- Explain your strategy for implementing `auto_avg`\n",
    "- Argue informally that your definition of `auto_avg` has a total privacy cost of `epsilon`\n",
    "- Did your solution work well for all three example columns? If it did not work well on any of them, why not?\n",
    "- When is your solution likely to *not* work well? (i.e. what properties does the data have to have, in order for your solution to not work well?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "def36546de73b2221e2699f4f41000a6",
     "grade": true,
     "grade_id": "cell-0ff63739ed66adf7",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Strategy for implementing auto_avg:\n",
    "- The strategy for auto_avg is to automatically clip the values in the Pandas series s based on its distribution (90th or 99th percentile) to limit the influence of extreme outliers. After clipping, I applied the Laplace mechanism to both the sum and the count of the clipped values, ensuring differential privacy while avoiding very small noisy counts by enforcing a lower bound.\n",
    "2. Total privacy cost of epsilon:\n",
    "- The function ensures that the total privacy cost is epsilon by splitting epsilon into two parts: one for the noisy sum and one for the noisy count, each receiving epsilon/2 or another balanced portion. The Laplace mechanism guarantees differential privacy with privacy loss parameter epsilon for each operation, ensuring the combined privacy cost doesn’t exceed the total epsilon.\n",
    "3. Solution performance for all columns:\n",
    "- The solution worked reasonably well for the ‘Age’ and ‘fnlwgt’ columns due to their relatively predictable distributions. However, for ‘Capital Gain,’ which has a more skewed distribution and extreme outliers, the method didn’t perform as well because clipping at the 99th percentile still left substantial variation, leading to higher errors.\n",
    "4. When the solution might not work well:\n",
    "- The solution is likely to fail on datasets with heavily skewed distributions, particularly when there are large outliers or long tails. In such cases, the chosen clipping thresholds might either be too aggressive (leading to loss of important data) or too loose (leading to insufficient noise reduction). Additionally, datasets with very small counts may introduce high variance when adding noise to the count."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
