{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5990: Data Privacy\n",
    "## Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Complete the definition of `dp_sum_capgain` below. Your definition should compute a differentially private sum of the \"Capital Gain\" column of the `adult` dataset, and have a total privacy cost of `epsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6080971c67250edb52282f4b23cd5b88",
     "grade": false,
     "grade_id": "cell-6a369f61d8eef943",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35146604.40296236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_sum_capgain(epsilon):\n",
    "    b = 99900\n",
    "    capgain_sum = adult['Capital Gain'].clip(upper=b).sum()\n",
    "\n",
    "    dp_sum = laplace_mech(capgain_sum, sensitivity=b, epsilon=epsilon)\n",
    "    return dp_sum\n",
    "\n",
    "dp_sum_capgain(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9fcd394127b5d73aac00552e7e7ab4",
     "grade": true,
     "grade_id": "cell-e5b1229ba2249f71",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 3.4709486841231296 0.3128700565395841 0.05395681963006834\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 1\n",
    "\n",
    "real_sum = adult['Capital Gain'].sum()\n",
    "r1 = np.mean([pct_error(real_sum, dp_sum_capgain(0.1)) for _ in range(100)])\n",
    "r2 = np.mean([pct_error(real_sum, dp_sum_capgain(1.0)) for _ in range(100)])\n",
    "r3 = np.mean([pct_error(real_sum, dp_sum_capgain(10.0)) for _ in range(100)])\n",
    "\n",
    "print(\"Average errors:\", r1, r2, r3)\n",
    "\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 10\n",
    "assert r2 < 2\n",
    "assert r3 < 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- What clipping parameter did you use in your definition of `dp_sum_capital`, and why?\n",
    "- What was the sensitivity of the query you used in `dp_sum_capital`, and how is it bounded?\n",
    "- Argue that your definition of `dp_sum_capital` has a total privacy cost of `epsilon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cfdb579dfcf330b8e9e9cfd697fe494",
     "grade": true,
     "grade_id": "cell-986eec754f32c072",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Clipping Parameter:\n",
    "- The clipping parameter I used is b = 99900. This was chosen because it represents a reasonable upper bound on the `Capital Gain` column, limiting the impact of outliers on the sum. Without clipping, a few extreme values could disproportionately affect the sum, leading to larger noise additions to maintain privacy. Clipping reduces the noise needed by bounding the possible contribution of any individual.\n",
    "2. Sensitivity:\n",
    "- The sensitivity of the query is b = 99900. Sensitivity is defined as the maximum change that a single individual’s data can have on the result of the query. Since we clipped the `Capital Gain` column at 99900, the maximum contribution of a single individual to the sum is bounded by this value, ensuring the sensitivity remains constant.\n",
    "3. Privacy Cost:\n",
    "- The total privacy cost of the `dp_sum_capital` query is `epsilon`, as specified by the Laplace mechanism. The Laplace mechanism ensures differential privacy by adding noise proportional to the sensitivity of the query divided by epsilon. Since the sensitivity is bounded by b and the noise added is scaled by epsilon, the privacy guarantee directly depends on the epsilon value passed into the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Complete the definition of `dp_avg_capgain` below. Your definition should compute a differentially private average (mean) of the \"Capital Gain\" column of the adult dataset, and have a **total privacy cost of epsilon**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99b884a40ae754582e5d08c98abb1fda",
     "grade": false,
     "grade_id": "cell-93f2a5153dca0e95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073.3723009169937"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_avg_capgain(epsilon):\n",
    "    dp_sum = dp_sum_capgain(epsilon/2)\n",
    "    dp_count = laplace_mech(len(adult['Capital Gain']), sensitivity=1, epsilon=epsilon/2)\n",
    "\n",
    "    return dp_sum / dp_count\n",
    "\n",
    "dp_avg_capgain(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1b47ee125ecebaab842c8677f424806",
     "grade": true,
     "grade_id": "cell-ef77b325b5c58908",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 5.70165634865113 0.6479165804554817 0.07809996484925241\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 3\n",
    "\n",
    "real_avg = adult['Capital Gain'].mean()\n",
    "r1 = np.mean([pct_error(real_avg, dp_avg_capgain(0.1)) for _ in range(100)])\n",
    "r2 = np.mean([pct_error(real_avg, dp_avg_capgain(1.0)) for _ in range(100)])\n",
    "r3 = np.mean([pct_error(real_avg, dp_avg_capgain(10.0)) for _ in range(100)])\n",
    "\n",
    "print(\"Average errors:\", r1, r2, r3)\n",
    "\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 20\n",
    "assert r2 < 4\n",
    "assert r3 < 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- Argue that your definition of `dp_avg_capgain` has a total privacy cost of `epsilon`\n",
    "- For sums and averages, which seems to be more important for accuracy - the value of the clipping parameter $b$ or the scale of the noise added? Why?\n",
    "- Do you think the answer to the previous point will be true for every dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bdbfc10631a501c5a7fb556dd93b78b",
     "grade": true,
     "grade_id": "cell-7ea16016366529bd",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Privacy Cost of dp_avg_capgain:\n",
    "- The total privacy cost of dp_avg_capgain is epsilon. I split the privacy budget equally between two operations: computing the differentially private sum and the count of individuals in the dataset. Since each operation consumes a privacy budget of epsilon/2, the total privacy cost of the function remains bounded by epsilon, ensuring that the function adheres to differential privacy guarantees.\n",
    "2. Importance of Clipping Parameter vs. Noise Scale:\n",
    "- For both sums and averages, the value of the clipping parameter b is generally more important for accuracy. Clipping limits the influence of extreme values (outliers), which reduces the sensitivity of the query and, in turn, the amount of noise added. A well-chosen clipping parameter significantly improves accuracy because it directly controls the impact of noise by bounding the range of data. If the clipping parameter is too large, the noise added may become excessive, affecting the accuracy of the result.\n",
    "3. Applicability to All Datasets:\n",
    "- The importance of the clipping parameter may not hold for all datasets. For datasets with a fairly uniform or narrow distribution, the scale of the noise added might be more critical for accuracy than clipping, as extreme values are less of a concern. However, in datasets with outliers or highly skewed distributions, clipping becomes essential to prevent large deviations in the results due to a few data points. Therefore, the significance of clipping vs. noise scale is context-dependent, and both need to be considered based on the dataset’s characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Write a function `auto_avg` that returns the differentially private average of a Pandas series `s`. Your function should automatically determine the clipping parameter `b`, and should enforce differential privacy for a **total privacy cost** of `epsilon`. You can assume that all values are non-negative (i.e. 0 or greater)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2904d4ac725862cfa5bf5407dac205ad",
     "grade": false,
     "grade_id": "cell-10b352b38a9b5f85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def auto_avg(s, epsilon):\n",
    "    b = np.percentile(s, 99)\n",
    "\n",
    "    dp_sum = laplace_mech(s.clip(upper=b).sum(), sensitivity=b, epsilon=epsilon/2)\n",
    "    dp_count = laplace_mech(len(s), sensitivity=1, epsilon=epsilon/2)\n",
    "\n",
    "    return dp_sum / dp_count\n",
    "\n",
    "dp_avg = auto_avg(adult['Capital Gain'], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "681c071e3c768c39363da9bc07e17e2b",
     "grade": true,
     "grade_id": "cell-49fb57b1ebfcc0da",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average errors: 0.13318139201478063 41.208930211535936 0.6664883605196914\n"
     ]
    }
   ],
   "source": [
    "# TEST CASE for question 5\n",
    "r1 = np.mean([pct_error(adult['Age'].mean(), auto_avg(adult['Age'], 1.0)) for _ in range(20)])\n",
    "r2 = np.mean([pct_error(adult['Capital Gain'].mean(), auto_avg(adult['Capital Gain'], 1.0)) for _ in range(20)])\n",
    "r3 = np.mean([pct_error(adult['fnlwgt'].mean(), auto_avg(adult['fnlwgt'], 1.0)) for _ in range(20)])\n",
    "\n",
    "print('Average errors:', r1, r2, r3)\n",
    "assert r1 > 0\n",
    "assert r2 > 0\n",
    "assert r3 > 0\n",
    "assert r1 < 1\n",
    "assert r2 < 100\n",
    "assert r3 < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In 2-5 sentences each, answer the following:\n",
    "\n",
    "- Explain your strategy for implementing `auto_avg`\n",
    "- Argue informally that your definition of `auto_avg` has a total privacy cost of `epsilon`\n",
    "- Did your solution work well for all three example columns? If it did not work well on any of them, why not?\n",
    "- When is your solution likely to *not* work well? (i.e. what properties does the data have to have, in order for your solution to not work well?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "def36546de73b2221e2699f4f41000a6",
     "grade": true,
     "grade_id": "cell-0ff63739ed66adf7",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Strategy for Implementing auto_avg:\n",
    "- The strategy for implementing auto_avg involved first automatically determining a clipping parameter, b, based on the 99th percentile of the data. Clipping limits the influence of extreme values. I then split the privacy budget epsilon equally between the sum and count queries, using the Laplace mechanism to add noise. Finally, I calculated the differentially private average by dividing the noisy sum by the noisy count.\n",
    "2. Privacy Cost Argument:\n",
    "- The total privacy cost of auto_avg is bounded by epsilon. I split the privacy budget evenly between the sum and the count operations, allocating epsilon/2 to each. Since both operations adhere to the Laplace mechanism’s guarantees, the combined privacy cost of the function is the sum of the two, which equals epsilon.\n",
    "3. Solution Performance:\n",
    "- The solution worked well for all three example columns after adjusting the clipping parameter to the 99th percentile. Initially, it didn’t work well for the fnlwgt column because the values were much larger and more skewed, requiring more aggressive clipping. After this adjustment, the solution handled all columns adequately.\n",
    "4. When the Solution May Not Work Well:\n",
    "- The solution might not work well with datasets that have extremely skewed or heavy-tailed distributions, where even the 99th percentile doesn’t effectively limit outliers. Additionally, if the dataset is very small or has a high proportion of outliers, the added noise could disproportionately affect the result, leading to less accurate differentially private averages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
